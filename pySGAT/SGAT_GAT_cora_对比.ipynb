{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGAT 把多头Attention和最后一层attention 的relu都去除 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Epoch: 0001 loss_train: 1.9515 acc_train: 0.1429 loss_val: 1.8655 acc_val: 0.6167 time: 17.0909s\n",
      "Epoch: 0002 loss_train: 1.8664 acc_train: 0.4571 loss_val: 1.7725 acc_val: 0.6433 time: 15.4748s\n",
      "Epoch: 0003 loss_train: 1.7389 acc_train: 0.5714 loss_val: 1.6598 acc_val: 0.6300 time: 15.5226s\n",
      "Epoch: 0004 loss_train: 1.6501 acc_train: 0.5214 loss_val: 1.5420 acc_val: 0.6300 time: 15.4000s\n",
      "Epoch: 0005 loss_train: 1.4929 acc_train: 0.5643 loss_val: 1.4262 acc_val: 0.6367 time: 15.3148s\n",
      "Epoch: 0006 loss_train: 1.3918 acc_train: 0.6143 loss_val: 1.3209 acc_val: 0.6600 time: 15.1961s\n",
      "Epoch: 0007 loss_train: 1.2544 acc_train: 0.6214 loss_val: 1.2238 acc_val: 0.6833 time: 15.5170s\n",
      "Epoch: 0008 loss_train: 1.2241 acc_train: 0.6357 loss_val: 1.1395 acc_val: 0.7267 time: 15.3409s\n",
      "Epoch: 0009 loss_train: 1.1314 acc_train: 0.6929 loss_val: 1.0662 acc_val: 0.7567 time: 15.3132s\n",
      "Epoch: 0010 loss_train: 0.9440 acc_train: 0.7643 loss_val: 1.0060 acc_val: 0.7867 time: 15.6712s\n",
      "Epoch: 0011 loss_train: 1.0276 acc_train: 0.7214 loss_val: 0.9548 acc_val: 0.8133 time: 16.7998s\n",
      "Epoch: 0012 loss_train: 0.9640 acc_train: 0.7500 loss_val: 0.9111 acc_val: 0.8200 time: 15.6195s\n",
      "Epoch: 0013 loss_train: 1.0238 acc_train: 0.7143 loss_val: 0.8764 acc_val: 0.8233 time: 15.6068s\n",
      "Epoch: 0014 loss_train: 0.8853 acc_train: 0.7500 loss_val: 0.8438 acc_val: 0.8133 time: 16.3631s\n",
      "Epoch: 0015 loss_train: 0.9869 acc_train: 0.7000 loss_val: 0.8152 acc_val: 0.8100 time: 15.2185s\n",
      "Epoch: 0016 loss_train: 0.7398 acc_train: 0.8214 loss_val: 0.7912 acc_val: 0.8167 time: 15.2857s\n",
      "Epoch: 0017 loss_train: 0.7151 acc_train: 0.7857 loss_val: 0.7683 acc_val: 0.8200 time: 15.3800s\n",
      "Epoch: 0018 loss_train: 0.8468 acc_train: 0.7571 loss_val: 0.7537 acc_val: 0.8233 time: 15.2570s\n",
      "Epoch: 0019 loss_train: 0.8363 acc_train: 0.7500 loss_val: 0.7416 acc_val: 0.8167 time: 15.4967s\n",
      "Epoch: 0020 loss_train: 0.6900 acc_train: 0.8214 loss_val: 0.7300 acc_val: 0.8200 time: 15.3111s\n",
      "Epoch: 0021 loss_train: 0.7455 acc_train: 0.7571 loss_val: 0.7208 acc_val: 0.8167 time: 15.4566s\n",
      "Epoch: 0022 loss_train: 0.8099 acc_train: 0.7500 loss_val: 0.7169 acc_val: 0.8267 time: 15.3212s\n",
      "Epoch: 0023 loss_train: 0.8028 acc_train: 0.7214 loss_val: 0.7114 acc_val: 0.8167 time: 15.2770s\n",
      "Epoch: 0024 loss_train: 0.7195 acc_train: 0.8143 loss_val: 0.7098 acc_val: 0.7967 time: 15.3495s\n",
      "Epoch: 0025 loss_train: 0.7486 acc_train: 0.8000 loss_val: 0.7059 acc_val: 0.7967 time: 15.2271s\n",
      "Epoch: 0026 loss_train: 0.8323 acc_train: 0.7429 loss_val: 0.6998 acc_val: 0.7967 time: 15.5827s\n",
      "Epoch: 0027 loss_train: 0.7759 acc_train: 0.7429 loss_val: 0.6926 acc_val: 0.8133 time: 15.3119s\n",
      "Epoch: 0028 loss_train: 0.6430 acc_train: 0.8143 loss_val: 0.6856 acc_val: 0.8100 time: 15.4043s\n",
      "Epoch: 0029 loss_train: 0.8084 acc_train: 0.7000 loss_val: 0.6775 acc_val: 0.8100 time: 15.4094s\n",
      "Epoch: 0030 loss_train: 0.7121 acc_train: 0.7357 loss_val: 0.6681 acc_val: 0.8067 time: 15.5523s\n",
      "Epoch: 0031 loss_train: 0.7054 acc_train: 0.7786 loss_val: 0.6577 acc_val: 0.8067 time: 15.4381s\n",
      "Epoch: 0032 loss_train: 0.8046 acc_train: 0.7357 loss_val: 0.6513 acc_val: 0.8133 time: 15.2768s\n",
      "Epoch: 0033 loss_train: 0.7282 acc_train: 0.7643 loss_val: 0.6474 acc_val: 0.8233 time: 15.4961s\n",
      "Epoch: 0034 loss_train: 0.7230 acc_train: 0.7786 loss_val: 0.6484 acc_val: 0.8333 time: 15.2270s\n",
      "Epoch: 0035 loss_train: 0.6918 acc_train: 0.8143 loss_val: 0.6509 acc_val: 0.8333 time: 15.3571s\n",
      "Epoch: 0036 loss_train: 0.6931 acc_train: 0.7571 loss_val: 0.6512 acc_val: 0.8367 time: 15.3585s\n",
      "Epoch: 0037 loss_train: 0.6836 acc_train: 0.7643 loss_val: 0.6538 acc_val: 0.8300 time: 15.4092s\n",
      "Epoch: 0038 loss_train: 0.6567 acc_train: 0.7714 loss_val: 0.6544 acc_val: 0.8300 time: 15.5838s\n",
      "Epoch: 0039 loss_train: 0.6341 acc_train: 0.7929 loss_val: 0.6547 acc_val: 0.8300 time: 15.5021s\n",
      "Epoch: 0040 loss_train: 0.6908 acc_train: 0.7857 loss_val: 0.6550 acc_val: 0.8333 time: 15.3375s\n",
      "Epoch: 0041 loss_train: 0.7762 acc_train: 0.7643 loss_val: 0.6534 acc_val: 0.8367 time: 15.5145s\n",
      "Epoch: 0042 loss_train: 0.6375 acc_train: 0.8214 loss_val: 0.6541 acc_val: 0.8267 time: 15.2886s\n",
      "Epoch: 0043 loss_train: 0.6897 acc_train: 0.7786 loss_val: 0.6585 acc_val: 0.8367 time: 15.3940s\n",
      "Epoch: 0044 loss_train: 0.6471 acc_train: 0.7714 loss_val: 0.6649 acc_val: 0.8233 time: 15.4686s\n",
      "Epoch: 0045 loss_train: 0.5518 acc_train: 0.8286 loss_val: 0.6734 acc_val: 0.8200 time: 15.2487s\n",
      "Epoch: 0046 loss_train: 0.6585 acc_train: 0.8071 loss_val: 0.6789 acc_val: 0.8200 time: 15.3240s\n",
      "Epoch: 0047 loss_train: 0.6297 acc_train: 0.8143 loss_val: 0.6802 acc_val: 0.8133 time: 15.4694s\n",
      "Epoch: 0048 loss_train: 0.6743 acc_train: 0.7714 loss_val: 0.6834 acc_val: 0.8100 time: 15.3882s\n",
      "Epoch: 0049 loss_train: 0.7615 acc_train: 0.7429 loss_val: 0.6871 acc_val: 0.8133 time: 15.5864s\n",
      "Epoch: 0050 loss_train: 0.7649 acc_train: 0.7357 loss_val: 0.6840 acc_val: 0.8133 time: 16.4354s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run trainSGAT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run trainGAT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5), squeeze=False)\n",
    "\n",
    "ax[0][0].plot(trainloss_SGAT_cora,label=\"losslist_cora_mymodel\")\n",
    "ax[0][0].legend(loc=0, ncol=1) \n",
    "ax[0][1].plot(valacc_SGAT_cora,label=\"valacclist_cora_mymodel\")\n",
    "ax[0][1].legend(loc=0, ncol=1) \n",
    "ax[0][0].plot(trainloss_GAT_cora,label=\"losslist_cora_GAT\")\n",
    "ax[0][0].legend(loc=0, ncol=1) \n",
    "ax[0][1].plot(valacc_GAT_cora,label=\"valacclist_cora_GAT\")\n",
    "ax[0][1].legend(loc=0, ncol=1) \n",
    "plt.savefig(\"GAT_SGAT在cora上对比\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aliatte]",
   "language": "python",
   "name": "conda-env-aliatte-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
